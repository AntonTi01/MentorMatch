# MentorMatch Matching Container

## Назначение
Сервис подбора, вычисляющий эмбеддинги пользователей и тем, а также формирующий рекомендации с помощью LLM. FastAPI приложение `matching/main.py` предоставляет REST-эндпоинты для обновления эмбеддингов и вызова различных сценариев подбора (по теме, роли, студенту и наставнику).【F:matching/main.py†L1-L120】

## Структура каталога
- `main.py` — настройка приложения, модели запросов и обработчики `/api/embeddings/*` и `/api/match/*`, которые открывают соединение с Postgres и вызывают доменные функции сервисного слоя.【F:matching/main.py†L1-L160】
- `service.py` — реализует бизнес-логику сопоставления: получает данные из репозитория, дополняет резюме, вызывает LLM для ранжирования и записывает результаты в базу при необходимости.【F:matching/service.py†L1-L140】
- `embeddings.py` — управление загрузкой и кэшированием моделей Sentence Transformers/Transformers, вычисление эмбеддингов и их сохранение в Postgres.【F:matching/embeddings.py†L1-L120】
- `repository.py` — SQL-выборки для получения тем, ролей, кандидатов и контекстных данных, используемых при подборе.【F:matching/repository.py†L1-L200】
- `llm.py` — обёртка над OpenAI API с функциями `rank_candidates`, `rank_topics`, `rank_roles`, обеспечивающая единообразное взаимодействие с моделью и обработку ошибок.【F:matching/llm.py†L1-L160】
- `payloads.py` — формирование JSON-представлений входных данных для LLM (кандидаты, роли, темы).【F:matching/payloads.py†L1-L160】
- `cv.py`, `text_extract.py` — извлечение текстов резюме и обработка медиа, используемые при обогащении кандидатов.【F:matching/cv.py†L1-L80】【F:matching/text_extract.py†L1-L120】
- `settings.py` — единая точка чтения переменных окружения (API ключи, температура LLM, директория моделей).【F:matching/settings.py†L1-L80】

## Ключевые функции
- `refresh_*_embedding()` — обработчики в `main.py`, которые вызывают функции из `embeddings.py` для пересчёта эмбеддингов студента, наставника, роли и темы и коммитят изменения в базе.【F:matching/main.py†L52-L119】【F:matching/embeddings.py†L1-L120】
- `handle_match()` — основной сценарий подбора по теме: собирает кандидатов, обогащает данные резюме, вызывает LLM и возвращает топ-5 рекомендаций с причинами. При недоступности модели выполняет резервный алгоритм на основе последних кандидатов.【F:matching/service.py†L41-L120】
- `handle_match_role()` и `handle_match_student()`/`handle_match_supervisor_user()` — вспомогательные сценарии подбора с различными входными сущностями, использующие общие функции payload/repository и fallback-логики.【F:matching/service.py†L141-L320】
- `create_matching_llm_client()` — создаёт клиента OpenAI с параметрами прокси и температурой из `settings.py`, используемого в обработчиках. При ошибках возвращает `None`, что активирует fallback-стратегии.【F:matching/llm.py†L1-L160】【F:matching/settings.py†L1-L80】

## Интеграции
- Использует Postgres для хранения эмбеддингов и результатов подбора, подключаясь через `db.get_conn()` (использует DSN из окружения).【F:matching/db.py†L1-L80】
- Доступ к моделям эмбеддингов осуществляется через локальный кеш `MODELS_DIR`, который может быть переопределён переменной `EMBEDDING_MODELS_DIR` и проброшен томом Docker.【F:matching/embeddings.py†L15-L34】【F:docker-compose.yml†L98-L112】
- Для более качественного ранжирования обращается к OpenAI API через прокси-параметры `PROXY_API_KEY`, `PROXY_BASE_URL`, `PROXY_MODEL`, задаваемые переменными окружения и описанные в `settings.py`.【F:matching/settings.py†L1-L80】
